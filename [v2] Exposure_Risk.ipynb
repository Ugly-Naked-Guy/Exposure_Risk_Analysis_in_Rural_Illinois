{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Flow Matrix Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the preprocessed dataset:\n",
    " - \"origin_dest_trips_census_tract_level.csv\"\n",
    " - \"tracts_4.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dataset is for the nested hashmap\n",
    "OD_p1_df = pd.read_csv('Streetlight_Data/clean_data/streetlight_OD_p1.csv')[['RESIDENCE','WORKPLACE','JOBS']]\n",
    "OD_p2_df = pd.read_csv('Streetlight_Data/clean_data/streetlight_OD_p2.csv')[['RESIDENCE','WORKPLACE','JOBS']]\n",
    "OD_p3_df = pd.read_csv('Streetlight_Data/clean_data/streetlight_OD_p3.csv')[['RESIDENCE','WORKPLACE','JOBS']]\n",
    "OD_p4_df = pd.read_csv('Streetlight_Data/clean_data/streetlight_OD_p4.csv')[['RESIDENCE','WORKPLACE','JOBS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>countyFIPS</th>\n",
       "      <th>estimate_cases1</th>\n",
       "      <th>estimate_cases2</th>\n",
       "      <th>estimate_cases3</th>\n",
       "      <th>estimate_cases4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17091011700</td>\n",
       "      <td>17091</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>27.107335</td>\n",
       "      <td>38.311700</td>\n",
       "      <td>116.471181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17091011800</td>\n",
       "      <td>17091</td>\n",
       "      <td>0.023156</td>\n",
       "      <td>20.840201</td>\n",
       "      <td>29.454151</td>\n",
       "      <td>89.543398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17119400951</td>\n",
       "      <td>17119</td>\n",
       "      <td>0.018442</td>\n",
       "      <td>10.548614</td>\n",
       "      <td>17.187603</td>\n",
       "      <td>142.941103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17119400952</td>\n",
       "      <td>17119</td>\n",
       "      <td>0.012385</td>\n",
       "      <td>7.084098</td>\n",
       "      <td>11.542621</td>\n",
       "      <td>95.994478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17135957500</td>\n",
       "      <td>17135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.240201</td>\n",
       "      <td>4.783816</td>\n",
       "      <td>74.692765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3118</th>\n",
       "      <td>17037000100</td>\n",
       "      <td>17037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.466793</td>\n",
       "      <td>35.104603</td>\n",
       "      <td>177.373983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119</th>\n",
       "      <td>17037001500</td>\n",
       "      <td>17037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.444589</td>\n",
       "      <td>19.911088</td>\n",
       "      <td>100.605297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>17037000400</td>\n",
       "      <td>17037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.713750</td>\n",
       "      <td>45.094142</td>\n",
       "      <td>227.848402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3121</th>\n",
       "      <td>17037000300</td>\n",
       "      <td>17037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.168505</td>\n",
       "      <td>14.016736</td>\n",
       "      <td>70.822746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3122</th>\n",
       "      <td>17037000200</td>\n",
       "      <td>17037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.020417</td>\n",
       "      <td>26.218619</td>\n",
       "      <td>132.475533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3123 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            GEOID  countyFIPS  estimate_cases1  estimate_cases2  \\\n",
       "0     17091011700       17091         0.030119        27.107335   \n",
       "1     17091011800       17091         0.023156        20.840201   \n",
       "2     17119400951       17119         0.018442        10.548614   \n",
       "3     17119400952       17119         0.012385         7.084098   \n",
       "4     17135957500       17135         0.000000         4.240201   \n",
       "...           ...         ...              ...              ...   \n",
       "3118  17037000100       17037         0.000000        25.466793   \n",
       "3119  17037001500       17037         0.000000        14.444589   \n",
       "3120  17037000400       17037         0.000000        32.713750   \n",
       "3121  17037000300       17037         0.000000        10.168505   \n",
       "3122  17037000200       17037         0.000000        19.020417   \n",
       "\n",
       "      estimate_cases3  estimate_cases4  \n",
       "0           38.311700       116.471181  \n",
       "1           29.454151        89.543398  \n",
       "2           17.187603       142.941103  \n",
       "3           11.542621        95.994478  \n",
       "4            4.783816        74.692765  \n",
       "...               ...              ...  \n",
       "3118        35.104603       177.373983  \n",
       "3119        19.911088       100.605297  \n",
       "3120        45.094142       227.848402  \n",
       "3121        14.016736        70.822746  \n",
       "3122        26.218619       132.475533  \n",
       "\n",
       "[3123 rows x 6 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_info_cases_data = pd.read_csv(\"Statistical_Analysis/data/ct_info_cases_data.csv\")\n",
    "ct_cases_df = ct_info_cases_data[['GEOID','countyFIPS','estimate_cases1','estimate_cases2','estimate_cases3','estimate_cases4']]\n",
    "ct_cases_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary: to record each origin->destination: number of trips\n",
    "\n",
    "use the dataset: OD_census_tract_level "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Generate a unique set of origins in commute trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Generate a doubly nested hashmap (python dictionary: key-value pair): \\\n",
    " first mapping: **origin -> destination** \\\n",
    " second mapping: **destination -> number of trips**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to fo defaultdict(defaultdict(int))\n",
    "# when {} is empty, enable\n",
    "# df['a']['b']+=1\n",
    "def defaultdict_float():\n",
    "    return defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8717fd0cbe90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mfip_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mnum_trips\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mnum_cases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mct_cases_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mct_cases_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GEOID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfip_o\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'estimate_cases1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_cases\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2789\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2791\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2793\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2843\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2844\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2845\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2847\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   3407\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3408\u001b[0m         \"\"\"\n\u001b[0;32m-> 3409\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3410\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   3393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m         new_data = self._data.take(\n\u001b[0;32m-> 3395\u001b[0;31m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3396\u001b[0m         )\n\u001b[1;32m   3397\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   1390\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Indices must be nonzero and less than the axis length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m         return self.reindex_indexer(\n\u001b[1;32m   1394\u001b[0m             \u001b[0mnew_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, allow_fill, fill_value, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \"\"\"\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_index_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"take\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_index_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# anuallly aggregated data \n",
    "# origin -> destination (county level) frequency dictionary\n",
    "# rename the origin-> destination df\n",
    "OD = OD_p1_df\n",
    "\n",
    "nu_OD_DblMap = defaultdict(defaultdict_float)\n",
    "num_ct = OD_p1_df.shape[0]\n",
    "\n",
    "for i in range(num_ct):\n",
    "    fip_o = OD.iloc[i,0]\n",
    "    fip_d = OD.iloc[i,1]\n",
    "    num_trips = OD.iloc[i,2]   \n",
    "    num_cases = float(ct_cases_df[ct_cases_df['GEOID'] == fip_o]['estimate_cases1'])\n",
    "    if num_cases == 0:\n",
    "        continue\n",
    "    else:\n",
    "        nu_OD_DblMap[fip_o][fip_d] = num_trips * num_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_OD_Map = defaultdict(float)\n",
    "for fip_d in nu_OD_DblMap:\n",
    "    sum = 0\n",
    "    for fip_o in nu_OD_DblMap:\n",
    "        sum += nu_OD_DblMap[fip_o][fip_d]\n",
    "    de_OD_Map[fip_d] = sum  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk_DblMap = defaultdict(defaultdict_float)\n",
    "for fip_o in nu_OD_DblMap:\n",
    "    for fip_d in nu_OD_DblMap[fip_o]:\n",
    "        nu = nu_OD_DblMap[fip_o][fip_d]\n",
    "        de = de_OD_Map[fip_d]\n",
    "        if de == 0 or nu == 0:\n",
    "            continue\n",
    "        else:               \n",
    "            Risk_DblMap[fip_o][fip_d] = nu/de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTotalRiskflow(OD, estimate_cases):\n",
    "    total_riskflow = 0\n",
    "    num_ct = OD.shape[0]\n",
    "    for i in range(num_ct):\n",
    "        fip_o = OD.iloc[i,0]\n",
    "        fip_d = OD.iloc[i,1]\n",
    "        num_trips = OD.iloc[i,2]   \n",
    "        num_cases = float(ct_cases_df[ct_cases_df['GEOID'] == fip_o][estimate_cases])\n",
    "        total_riskflow += num_trips*num_cases/10**6\n",
    "    return total_riskflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_riskflow1 = getTotalRiskflow(OD = OD_p1_df, \n",
    "                 estimate_cases = 'estimate_cases1')\n",
    "total_riskflow2= getTotalRiskflow(OD = OD_p2_df, \n",
    "                 estimate_cases = 'estimate_cases2')\n",
    "total_riskflow3 = getTotalRiskflow(OD = OD_p3_df, \n",
    "                 estimate_cases = 'estimate_cases3')\n",
    "total_riskflow4 = getTotalRiskflow(OD = OD_p4_df, \n",
    "                 estimate_cases = 'estimate_cases4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-217-5dac5e60f26c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtotal_riskflow4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'keys'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new\n",
    "def getDPTotalRisk(OD, estimate_cases, apple_mobility):\n",
    "    nu_OD_DblMap = defaultdict(defaultdict_float)\n",
    "    num_ct = OD.shape[0]\n",
    "    total_riskflow = 0\n",
    "\n",
    "    for i in range(num_ct):\n",
    "        fip_o = OD.iloc[i,0]\n",
    "        fip_d = OD.iloc[i,1]\n",
    "        num_trips = OD.iloc[i,2]   \n",
    "        num_cases = float(ct_cases_df[ct_cases_df['GEOID'] == fip_o][estimate_cases])\n",
    "        total_riskflow += num_trips * num_cases \n",
    "        if num_cases == 0:\n",
    "            continue\n",
    "        else:\n",
    "            nu_OD_DblMap[fip_o][fip_d] = num_trips * num_cases\n",
    "        \n",
    "    for fip_o in nu_OD_DblMap:\n",
    "        for fip_d in nu_OD_DblMap[fip_o]:\n",
    "            if nu_OD_DblMap[fip_o][fip_d] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                nu_OD_DblMap[fip_o][fip_d] = nu_OD_DblMap[fip_o][fip_d]/total_riskflow * apple_mobility\n",
    "    print(total_riskflow)       \n",
    "    return nu_OD_DblMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3116"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(OD_p4_df.iloc[:,0].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "dptotal_Risk_DblMap1 =  getDPTotalRisk(OD = OD_p1_df, \n",
    "                                         estimate_cases = 'estimate_cases1',\n",
    "                                         apple_mobility = 109.278621/100)\n",
    "dptotal_Risk_DblMap2 =  getDPTotalRisk(OD = OD_p2_df,\n",
    "                                         estimate_cases = 'estimate_cases2',\n",
    "                                         apple_mobility = 73.2133333/100)\n",
    "dptotal_Risk_DblMap3 =  getDPTotalRisk(OD = OD_p3_df,\n",
    "                                         estimate_cases = 'estimate_cases3',\n",
    "                                         apple_mobility = 130.970323/100)\n",
    "dptotal_Risk_DblMap4 =  getDPTotalRisk(OD = OD_p4_df,\n",
    "                                         estimate_cases = 'estimate_cases4',\n",
    "                                         apple_mobility = 139.87/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0\n",
    "count = 0\n",
    "for i in dptotal_Risk_DblMap3 :\n",
    "    for j in dptotal_Risk_DblMap3[i]:\n",
    "        if dptotal_Risk_DblMap3[i][j] == 0:\n",
    "            count += 1\n",
    "        sum += dptotal_Risk_DblMap3[i][j]\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dptotal_Risk_DblMap = [dptotal_Risk_DblMap1, dptotal_Risk_DblMap2, \n",
    "                             dptotal_Risk_DblMap3, dptotal_Risk_DblMap4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer double risk map to csv file and save to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveRiskflowToCSV(Risk_DblMap, path):\n",
    "    riskflow_df = pd.DataFrame(columns = ('START', 'END', 'RISK_FLOW'))\n",
    "    for fip_o in Risk_DblMap:\n",
    "        for fip_d in Risk_DblMap[fip_o]:\n",
    "            riskflow = Risk_DblMap[fip_o][fip_d]\n",
    "        new_row = pd.DataFrame({'START':[fip_o], 'END':[fip_d], 'RISK_FLOW': [riskflow] })\n",
    "        riskflow_df = riskflow_df.append(new_row)\n",
    "    riskflow_df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveRiskflowToCSV(Risk_DblMap = dptotal_Risk_DblMap1, \n",
    "                  path = 'Streetlight_Data/clean_data/dptotal/dptotal_riskflow1_df.csv')\n",
    "saveRiskflowToCSV(Risk_DblMap = dptotal_Risk_DblMap2, \n",
    "                  path = 'Streetlight_Data/clean_data/dptotal/dptotal_riskflow2_df.csv')\n",
    "saveRiskflowToCSV(Risk_DblMap = dptotal_Risk_DblMap3, \n",
    "                  path = 'Streetlight_Data/clean_data/dptotal/dptotal_riskflow3_df.csv')\n",
    "saveRiskflowToCSV(Risk_DblMap = dptotal_Risk_DblMap4, \n",
    "                  path = 'Streetlight_Data/clean_data/dptotal/dptotal_riskflow4_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculaye exposure entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExposure(Risk_DblMap):\n",
    "#     reverse_Risk_DblMap = defaultdict(defaultdict_float)\n",
    "#     for fip_o in Risk_DblMap:\n",
    "#         for fip_d in Risk_DblMap[fip_o]:\n",
    "#             risk = Risk_DblMap[fip_o][fip_d]   \n",
    "#             if risk == 0:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 reverse_Risk_DblMap[fip_d][fip_o] = risk\n",
    "\n",
    "    Exposure_Map = {}\n",
    "    for fip_d in Risk_DblMap:\n",
    "        v = np.array(list(Risk_DblMap[fip_d].values()))\n",
    "        v[v == 0] = 10**-10\n",
    "        logv = np.log(v)\n",
    "        entropy = - np.sum(v * logv)\n",
    "        Exposure_Map[fip_d] = entropy\n",
    "    return Exposure_Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exposure_Map1 = getExposure(dptotal_Risk_DblMap1)\n",
    "Exposure_Map2 = getExposure(dptotal_Risk_DblMap2)\n",
    "Exposure_Map3 = getExposure(dptotal_Risk_DblMap3)\n",
    "Exposure_Map4 = getExposure(dptotal_Risk_DblMap4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>exposure1</th>\n",
       "      <th>exposure2</th>\n",
       "      <th>exposure3</th>\n",
       "      <th>exposure4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17001000100</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.006664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17001000201</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.001351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17001000202</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.002302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17001000400</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.003059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17001000500</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.001462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17203030501</td>\n",
       "      <td>0.010959</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.007808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17203030502</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17203030601</td>\n",
       "      <td>0.008321</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.005981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17203030602</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.001671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17203030700</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.001994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2502 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           FIPS  exposure1  exposure2  exposure3  exposure4\n",
       "0   17001000100   0.001941   0.000319   0.000838   0.006664\n",
       "0   17001000201   0.000384   0.000062   0.000164   0.001351\n",
       "0   17001000202   0.000660   0.000107   0.000283   0.002302\n",
       "0   17001000400   0.000880   0.000143   0.000377   0.003059\n",
       "0   17001000500   0.000418   0.000067   0.000179   0.001462\n",
       "..          ...        ...        ...        ...        ...\n",
       "0   17203030501   0.010959   0.000454   0.001102   0.007808\n",
       "0   17203030502   0.001048   0.000041   0.000101   0.000741\n",
       "0   17203030601   0.008321   0.000359   0.000861   0.005981\n",
       "0   17203030602   0.002334   0.000094   0.000230   0.001671\n",
       "0   17203030700   0.002778   0.000116   0.000280   0.001994\n",
       "\n",
       "[2502 rows x 5 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exposure_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure_df = pd.DataFrame(columns = ('FIPS', 'exposure1', 'exposure2', 'exposure3', 'exposure4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.84035746719779"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(exposure_df['exposure4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, fip_d in enumerate(Exposure_Map1): \n",
    "    FIPS = str(fip_d)\n",
    "    exposure1 = Exposure_Map1[fip_d]\n",
    "    exposure2 = Exposure_Map2[fip_d]\n",
    "    exposure3 = Exposure_Map3[fip_d]\n",
    "    exposure4 = Exposure_Map4.get(fip_d, 0) \n",
    "    new_row = pd.DataFrame({'FIPS':[FIPS], 'exposure1':[exposure1],\n",
    "                        'exposure2':[exposure2], 'exposure3':[exposure3],\n",
    "                        'exposure4':[exposure4]})\n",
    "    exposure_df = exposure_df.append( new_row )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure_df.to_csv('Streetlight_Data/clean_data/dptotal/dptotal_exposure_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveExposureToCSV(list_Risk_DblMap, path):\n",
    "    Exposure_Map1 = getExposure(list_Risk_DblMap[0])\n",
    "    Exposure_Map2 = getExposure(list_Risk_DblMap[1])\n",
    "    Exposure_Map3 = getExposure(list_Risk_DblMap[2])\n",
    "    Exposure_Map4 = getExposure(list_Risk_DblMap[3])\n",
    "    \n",
    "    exposure_df = pd.DataFrame(columns = ('FIPS', 'exposure1', 'exposure2', 'exposure3', 'exposure4'))\n",
    "    \n",
    "    for i, fip_d in enumerate(Exposure_Map1): \n",
    "        FIPS = str(fip_d)\n",
    "        exposure1 = Exposure_Map1[fip_d]\n",
    "        exposure2 = Exposure_Map2[fip_d]\n",
    "        exposure3 = Exposure_Map3[fip_d]\n",
    "        exposure4 = Exposure_Map4.get(fip_d, 0) \n",
    "        new_row = pd.DataFrame({'FIPS':[FIPS], 'exposure1':[exposure1],\n",
    "                            'exposure2':[exposure2], 'exposure3':[exposure3],\n",
    "                            'exposure4':[exposure4]})\n",
    "        exposure_df = exposure_df.append(new_row)\n",
    "    \n",
    "    exposure_df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveExposureToCSV(list_dptotal_Risk_DblMap, 'Streetlight_Data/clean_data/dptotal/dptotal_exposure_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
