{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Flow Matrix Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the preprocessed dataset:\n",
    " - \"origin_dest_trips_census_tract_level.csv\"\n",
    " - \"tracts_4.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dataset is for the nested hashmap\n",
    "OD_p1_df = pd.read_csv('Streetlight_Data/clean_data/streetlight_OD_p1.csv')[['RESIDENCE','WORKPLACE','JOBS']]\n",
    "OD_p2_df = pd.read_csv('Streetlight_Data/clean_data/streetlight_OD_p2.csv')[['RESIDENCE','WORKPLACE','JOBS']]\n",
    "OD_p3_df = pd.read_csv('Streetlight_Data/clean_data/streetlight_OD_p3.csv')[['RESIDENCE','WORKPLACE','JOBS']]\n",
    "OD_p4_df = pd.read_csv('Streetlight_Data/clean_data/streetlight_OD_p4.csv')[['RESIDENCE','WORKPLACE','JOBS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RESIDENCE</th>\n",
       "      <th>WORKPLACE</th>\n",
       "      <th>JOBS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17001000100</td>\n",
       "      <td>17001000100</td>\n",
       "      <td>5005.177622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17001000100</td>\n",
       "      <td>17001000201</td>\n",
       "      <td>432.101665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17001000100</td>\n",
       "      <td>17001000202</td>\n",
       "      <td>324.076249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17001000100</td>\n",
       "      <td>17001000400</td>\n",
       "      <td>360.084721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17001000100</td>\n",
       "      <td>17001000500</td>\n",
       "      <td>4285.008180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80423</th>\n",
       "      <td>17203030700</td>\n",
       "      <td>17113005102</td>\n",
       "      <td>46.336570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80424</th>\n",
       "      <td>17203030700</td>\n",
       "      <td>17143001600</td>\n",
       "      <td>36.275552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80425</th>\n",
       "      <td>17203030700</td>\n",
       "      <td>17179021201</td>\n",
       "      <td>155.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80426</th>\n",
       "      <td>17203030700</td>\n",
       "      <td>17203030601</td>\n",
       "      <td>480.273810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80427</th>\n",
       "      <td>17203030700</td>\n",
       "      <td>17203030700</td>\n",
       "      <td>7924.517857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80428 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         RESIDENCE    WORKPLACE         JOBS\n",
       "0      17001000100  17001000100  5005.177622\n",
       "1      17001000100  17001000201   432.101665\n",
       "2      17001000100  17001000202   324.076249\n",
       "3      17001000100  17001000400   360.084721\n",
       "4      17001000100  17001000500  4285.008180\n",
       "...            ...          ...          ...\n",
       "80423  17203030700  17113005102    46.336570\n",
       "80424  17203030700  17143001600    36.275552\n",
       "80425  17203030700  17179021201   155.851852\n",
       "80426  17203030700  17203030601   480.273810\n",
       "80427  17203030700  17203030700  7924.517857\n",
       "\n",
       "[80428 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OD_p1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>countyFIPS</th>\n",
       "      <th>estimate_cases1</th>\n",
       "      <th>estimate_cases2</th>\n",
       "      <th>estimate_cases3</th>\n",
       "      <th>estimate_cases4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17091011700</td>\n",
       "      <td>17091</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>27.107335</td>\n",
       "      <td>38.311700</td>\n",
       "      <td>116.471181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17091011800</td>\n",
       "      <td>17091</td>\n",
       "      <td>0.023156</td>\n",
       "      <td>20.840201</td>\n",
       "      <td>29.454151</td>\n",
       "      <td>89.543398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17119400951</td>\n",
       "      <td>17119</td>\n",
       "      <td>0.018442</td>\n",
       "      <td>10.548614</td>\n",
       "      <td>17.187603</td>\n",
       "      <td>142.941103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17119400952</td>\n",
       "      <td>17119</td>\n",
       "      <td>0.012385</td>\n",
       "      <td>7.084098</td>\n",
       "      <td>11.542621</td>\n",
       "      <td>95.994478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17135957500</td>\n",
       "      <td>17135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.240201</td>\n",
       "      <td>4.783816</td>\n",
       "      <td>74.692765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3118</th>\n",
       "      <td>17037000100</td>\n",
       "      <td>17037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.466793</td>\n",
       "      <td>35.104603</td>\n",
       "      <td>177.373983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119</th>\n",
       "      <td>17037001500</td>\n",
       "      <td>17037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.444589</td>\n",
       "      <td>19.911088</td>\n",
       "      <td>100.605297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>17037000400</td>\n",
       "      <td>17037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.713750</td>\n",
       "      <td>45.094142</td>\n",
       "      <td>227.848402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3121</th>\n",
       "      <td>17037000300</td>\n",
       "      <td>17037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.168505</td>\n",
       "      <td>14.016736</td>\n",
       "      <td>70.822746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3122</th>\n",
       "      <td>17037000200</td>\n",
       "      <td>17037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.020417</td>\n",
       "      <td>26.218619</td>\n",
       "      <td>132.475533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3123 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            GEOID  countyFIPS  estimate_cases1  estimate_cases2  \\\n",
       "0     17091011700       17091         0.030119        27.107335   \n",
       "1     17091011800       17091         0.023156        20.840201   \n",
       "2     17119400951       17119         0.018442        10.548614   \n",
       "3     17119400952       17119         0.012385         7.084098   \n",
       "4     17135957500       17135         0.000000         4.240201   \n",
       "...           ...         ...              ...              ...   \n",
       "3118  17037000100       17037         0.000000        25.466793   \n",
       "3119  17037001500       17037         0.000000        14.444589   \n",
       "3120  17037000400       17037         0.000000        32.713750   \n",
       "3121  17037000300       17037         0.000000        10.168505   \n",
       "3122  17037000200       17037         0.000000        19.020417   \n",
       "\n",
       "      estimate_cases3  estimate_cases4  \n",
       "0           38.311700       116.471181  \n",
       "1           29.454151        89.543398  \n",
       "2           17.187603       142.941103  \n",
       "3           11.542621        95.994478  \n",
       "4            4.783816        74.692765  \n",
       "...               ...              ...  \n",
       "3118        35.104603       177.373983  \n",
       "3119        19.911088       100.605297  \n",
       "3120        45.094142       227.848402  \n",
       "3121        14.016736        70.822746  \n",
       "3122        26.218619       132.475533  \n",
       "\n",
       "[3123 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_info_cases_data = pd.read_csv(\"Statistical_Analysis/data/ct_info_cases_data.csv\")\n",
    "ct_cases_df = ct_info_cases_data[['GEOID','countyFIPS','estimate_cases1','estimate_cases2','estimate_cases3','estimate_cases4']]\n",
    "ct_cases_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary: to record each origin->destination: number of trips\n",
    "\n",
    "use the dataset: OD_census_tract_level "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Generate a unique set of origins in commute trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Generate a doubly nested hashmap (python dictionary: key-value pair): \\\n",
    " first mapping: **origin -> destination** \\\n",
    " second mapping: **destination -> number of trips**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to fo defaultdict(defaultdict(int))\n",
    "# when {} is empty, enable\n",
    "# df['a']['b']+=1\n",
    "def defaultdict_float():\n",
    "    return defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anuallly aggregated data \n",
    "# origin -> destination (county level) frequency dictionary\n",
    "# rename the origin-> destination df\n",
    "OD = OD_p1_df\n",
    "\n",
    "nu_OD_DblMap = defaultdict(defaultdict_float)\n",
    "num_ct = OD_p1_df.shape[0]\n",
    "\n",
    "for i in range(num_ct):\n",
    "    fip_o = OD.iloc[i,0]\n",
    "    fip_d = OD.iloc[i,1]\n",
    "    num_trips = OD.iloc[i,2]   \n",
    "    num_cases = float(ct_cases_df[ct_cases_df['GEOID'] == fip_o]['estimate_cases1'])\n",
    "    if num_cases == 0:\n",
    "        continue\n",
    "    else:\n",
    "        nu_OD_DblMap[fip_o][fip_d] = num_trips * num_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_OD_Map = defaultdict(float)\n",
    "for fip_d in nu_OD_DblMap:\n",
    "    sum = 0\n",
    "    for fip_o in nu_OD_DblMap:\n",
    "        sum += nu_OD_DblMap[fip_o][fip_d]\n",
    "    de_OD_Map[fip_d] = sum  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk_DblMap = defaultdict(defaultdict_float)\n",
    "for fip_o in nu_OD_DblMap:\n",
    "    for fip_d in nu_OD_DblMap[fip_o]:\n",
    "        nu = nu_OD_DblMap[fip_o][fip_d]\n",
    "        de = de_OD_Map[fip_d]\n",
    "        if de == 0 or nu == 0:\n",
    "            continue\n",
    "        else:               \n",
    "            Risk_DblMap[fip_o][fip_d] = nu/de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new\n",
    "def getUnnormalizedRisk(OD, estimate_cases):\n",
    "    nu_OD_DblMap = defaultdict(defaultdict_float)\n",
    "    num_ct = OD.shape[0]\n",
    "\n",
    "    for i in range(num_ct):\n",
    "        fip_o = OD.iloc[i,0]\n",
    "        fip_d = OD.iloc[i,1]\n",
    "        num_trips = OD.iloc[i,2]   \n",
    "        num_cases = float(ct_cases_df[ct_cases_df['GEOID'] == fip_o]['estimate_cases1'])\n",
    "        if num_cases == 0:\n",
    "            continue\n",
    "        else:\n",
    "            nu_OD_DblMap[fip_o][fip_d] = num_trips * num_cases\n",
    "    return nu_OD_DblMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRisk(OD, estimate_cases):      \n",
    "    nu_OD_DblMap = defaultdict(defaultdict_float)\n",
    "    num_ct = OD.shape[0]\n",
    "    for i in range(num_ct):\n",
    "        fip_o = OD.iloc[i,0]\n",
    "        fip_d = OD.iloc[i,1]\n",
    "        num_trips = OD.iloc[i,2]   \n",
    "        num_cases = float(ct_cases_df[ct_cases_df['GEOID'] == fip_o]['estimate_cases1'])\n",
    "        if num_cases == 0:\n",
    "            continue\n",
    "        else:\n",
    "            nu_OD_DblMap[fip_o][fip_d] = num_trips * num_cases\n",
    "\n",
    "    de_OD_Map = defaultdict(float)\n",
    "    for fip_d in nu_OD_DblMap:\n",
    "        sum = 0\n",
    "        for fip_o in nu_OD_DblMap:\n",
    "            sum += nu_OD_DblMap[fip_o][fip_d]\n",
    "        de_OD_Map[fip_d] = sum  \n",
    "\n",
    "    Risk_DblMap = defaultdict(defaultdict_float)\n",
    "    for fip_o in nu_OD_DblMap:\n",
    "        for fip_d in nu_OD_DblMap[fip_o]:\n",
    "            nu = nu_OD_DblMap[fip_o][fip_d]\n",
    "            de = de_OD_Map[fip_d]\n",
    "            if de == 0 or nu == 0:\n",
    "                continue\n",
    "            else:               \n",
    "                Risk_DblMap[fip_o][fip_d] = nu/de\n",
    "    return Risk_DblMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "unor_Risk_DblMap1 =  getUnnormalizedRisk(OD = OD_p1_df, \n",
    "                       estimate_cases = 'estimate_cases1')\n",
    "unor_Risk_DblMap2 =  getUnnormalizedRisk(OD = OD_p2_df, \n",
    "                       estimate_cases = 'estimate_cases2')\n",
    "unor_Risk_DblMap3 =  getUnnormalizedRisk(OD = OD_p3_df, \n",
    "                       estimate_cases = 'estimate_cases3')\n",
    "unor_Risk_DblMap4 =  getUnnormalizedRisk(OD = OD_p4_df,\n",
    "                       estimate_cases = 'estimate_cases4')         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk_DblMap1 = getRisk(OD = OD_p1_df, \n",
    "                       estimate_cases = 'estimate_cases1')\n",
    "Risk_DblMap2 = getRisk(OD = OD_p2_df, \n",
    "                       estimate_cases = 'estimate_cases2')\n",
    "Risk_DblMap3 = getRisk(OD = OD_p3_df, \n",
    "                       estimate_cases = 'estimate_cases3')\n",
    "Risk_DblMap4 = getRisk(OD = OD_p4_df,\n",
    "                       estimate_cases = 'estimate_cases4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer double risk map to csv file and save to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveRiskflowToCSV(Risk_DblMap, path):\n",
    "    riskflow_df = pd.DataFrame(columns = ('START', 'END', 'RISK_FLOW'))\n",
    "    for fip_o in Risk_DblMap:\n",
    "        for fip_d in Risk_DblMap[fip_o]:\n",
    "            riskflow = Risk_DblMap[fip_o][fip_d]\n",
    "        new_row = pd.DataFrame({'START':[fip_o], 'END':[fip_d], 'RISK_FLOW': [riskflow] })\n",
    "        riskflow_df = riskflow_df.append(new_row)\n",
    "    riskflow_df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveRiskflowToCSV(Risk_DblMap = unor_Risk_DblMap1, \n",
    "                  path = 'Streetlight_Data/clean_data/unor_riskflow1_df.csv')\n",
    "saveRiskflowToCSV(Risk_DblMap = unor_Risk_DblMap2, \n",
    "                  path = 'Streetlight_Data/clean_data/unor_riskflow2_df.csv')\n",
    "saveRiskflowToCSV(Risk_DblMap = unor_Risk_DblMap3, \n",
    "                  path = 'Streetlight_Data/clean_data/unor_riskflow3_df.csv')\n",
    "saveRiskflowToCSV(Risk_DblMap = unor_Risk_DblMap4, \n",
    "                  path = 'Streetlight_Data/clean_data/unor_riskflow4_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveRiskflowToCSV(Risk_DblMap = Risk_DblMap1, \n",
    "                  path = 'Streetlight_Data/clean_data/riskflow1_df.csv')\n",
    "saveRiskflowToCSV(Risk_DblMap = Risk_DblMap2, \n",
    "                  path = 'Streetlight_Data/clean_data/riskflow2_df.csv')\n",
    "saveRiskflowToCSV(Risk_DblMap = Risk_DblMap3, \n",
    "                  path = 'Streetlight_Data/clean_data/riskflow3_df.csv')\n",
    "saveRiskflowToCSV(Risk_DblMap = Risk_DblMap4, \n",
    "                  path = 'Streetlight_Data/clean_data/riskflow4_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculaye exposure entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dictionary changed size during iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-2f0ffac357da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfip_d\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mRisk_DblMap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfip_o\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mRisk_DblMap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfip_o\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0msum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mRisk_DblMap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfip_o\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfip_d\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mde_Risk_Map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfip_d\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dictionary changed size during iteration"
     ]
    }
   ],
   "source": [
    "# Exposure_Map = defaultdict(defaultdict_float)\n",
    "de_Risk_Map = defaultdict(float)\n",
    "for fip_d in Risk_DblMap:\n",
    "    sum = 0\n",
    "    for fip_o in Risk_DblMap[fip_o]:\n",
    "        sum += Risk_DblMap[fip_o][fip_d]\n",
    "    de_Risk_Map[fip_d] = sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_Risk_DblMap = defaultdict(defaultdict_float)\n",
    "for fip_o in Risk_DblMap:\n",
    "    for fip_d in Risk_DblMap[fip_o]:\n",
    "        risk = Risk_DblMap[fip_o][fip_d]   \n",
    "        if risk == 0:\n",
    "            continue\n",
    "        else:\n",
    "            reverse_Risk_DblMap[fip_d][fip_o] = risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(list(reverse_Risk_DblMap[17031811701].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exposure_Map = {}\n",
    "for fip_d in reverse_Risk_DblMap:\n",
    "    v = np.array(list(reverse_Risk_DblMap[fip_d].values()))\n",
    "    logv = np.log(v)\n",
    "    entropy = - np.sum(v * logv)\n",
    "    Exposure_Map[fip_d] = entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExposure(Risk_DblMap):\n",
    "    reverse_Risk_DblMap = defaultdict(defaultdict_float)\n",
    "    for fip_o in Risk_DblMap:\n",
    "        for fip_d in Risk_DblMap[fip_o]:\n",
    "            risk = Risk_DblMap[fip_o][fip_d]   \n",
    "            if risk == 0:\n",
    "                continue\n",
    "            else:\n",
    "                reverse_Risk_DblMap[fip_d][fip_o] = risk\n",
    "\n",
    "    Exposure_Map = {}\n",
    "    for fip_d in reverse_Risk_DblMap:\n",
    "        v = np.array(list(reverse_Risk_DblMap[fip_d].values()))\n",
    "        logv = np.log(v)\n",
    "        entropy = - np.sum(v * logv)\n",
    "        Exposure_Map[fip_d] = entropy\n",
    "    return Exposure_Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exposure_Map1 = getExposure(Risk_DblMap1)\n",
    "Exposure_Map2 = getExposure(Risk_DblMap2)\n",
    "Exposure_Map3 = getExposure(Risk_DblMap3)\n",
    "Exposure_Map4 = getExposure(Risk_DblMap4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure_df = pd.DataFrame(columns = ('FIPS', 'exposure1', 'exposure2', 'exposure3', 'exposure4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, fip_d in enumerate(Exposure_Map1): \n",
    "    FIPS = str(fip_d)\n",
    "    exposure1 = Exposure_Map1[fip_d]\n",
    "    exposure2 = Exposure_Map2[fip_d]\n",
    "    exposure3 = Exposure_Map3[fip_d]\n",
    "    exposure4 = Exposure_Map4[fip_d] \n",
    "    new_row = pd.DataFrame({'FIPS':[FIPS], 'exposure1':[exposure1],\n",
    "                        'exposure2':[exposure2], 'exposure3':[exposure3],\n",
    "                        'exposure4':[exposure4]})\n",
    "    exposure_df = exposure_df.append( new_row )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure_df.to_csv('Streetlight_Data/clean_data/exposure_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
